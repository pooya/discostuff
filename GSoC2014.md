* Website: http://discoproject.org/
* Responsible: Shayan Pooya, Prashanth Mundkur
* If you have any questions, send an e-mail to beam-community@googlegroups.com.

Ideas are listed in no particular order.

### Idea #1:  Disco worker in more efficient programming languages.

Brief explanation:  The default disco worker is written in Python.  Python is very simple and there are a lot of tools availabe for it.  However, there are certain jobs and usecases that need more efficient languages.  That is why the worker protocol has been abstracted out and some worker protocols in other languages (OCaml and Java) have been created.  The objective of this project is to implement a golang or haskell worker.  The workers should be general purpose, extensible and it should be simple and flexible to extend these workers to create new workers to do various tasks.

Expected results: A worker in haskell or golang that can be extended to write different types of workers.

Knowledge prerequisites: Python, Erlang, and golang or haskell

Mentors: Shayan Pooya, Prashanth Mundkur

### Idea #2:  DDFS testing using Local-Cluster mode.

Brief explanation:  Testing a particular distributed system generally requires significant investment in a distributed testing harness, especially when it comes to supporting _reproducible_ automated tests.  This normally means that testing the fault-tolerance and safety of a distributed filesystem like DDFS requires a fair amount of work.

However, DDFS now has the capability to simulate a cluster in a single machine (the 'local cluster' mode).  This means that we can test the fault-tolerance, garbage collection and replication features of DDFS using a single machine, in an automated and easy-to-reproduce way.

Expected results:  This project would involve writing a testing library and tests that use the local-cluster mode to test GC and replication in DDFS.

Knowledge prerequisites:  Distributed systems, Erlang, Python.

Mentors:  Shayan Pooya, Prashanth Mundkur

### Idea #3:  Improving security of Disco workers

Brief explanation:  Currently, Disco workers run completely untrusted code that has full access to a node's filesystem, and hence also to intermediate data generated by other jobs and any DDFS data on that node.

This project would explore techniques to sandbox the Disco worker process in a manner that is easy to port to exploit sandboxing features supported by different OSes.  The portability should be tested by targeting the implementation at least two of (a) Linux namespaces/containers, (b) MacOSX sandbox(7), (c) FreeBSD Capsicum.

An alternative could be to provide a specialized Disco worker that uses the Google Native Client framework to sandbox.

Expected results:  A prototype of a portable sandboxed Disco worker.

Knowledge prerequisites:  Operating systems, security.

Mentors:  Shayan Pooya, Prashanth Mundkur

### Idea #4:  Property testing of the pipelined job scheduler

Brief explanation:  The new Disco job scheduler was explicitly written in a way to make it easy to test with Erlang's property testing tools like Proper/Triq/Quickcheck.  There are already some basic tests for low-level functionality.  This project would create property tests that eventually cover the entire pipeline scheduling code.

There are other areas of Disco that could also benefit from modularized property testing that the applicant could choose to work on.

Expected results:  A property-testing test suite.

Knowledge prerequisites:  Erlang.

Mentors:  Shayan Pooya, Prashanth Mundkur

### Idea #5:  Network-resource-aware task allocator

Brief explanation:  The current mechanism of allocating tasks to cluster nodes uses a very naive idea of the network topology of the cluster, especially of the rack-locality of cluster nodes.  It would be good to address this taking into account the dynamic network topology present in an environment like AWS (as opposed to assuming a static environment).

There are two components for this project: (a) infer or extract the current cluster network topology while requiring the absolute minimum of user-configuration (ideally none), and (b) exploiting this network topology in a new task allocator algorithm that minimizes network impact of task allocations.

A stretch goal would be to also use this topology in DDFS to minimize network impact of replication and improving replica placement to handle rack-level outages.

Expected results:  A prototype for an improved network-aware task scheduler.

Knowledge prerequisites:  Networking, Erlang.

Mentors:  Shayan Pooya, Prashanth Mundkur


### Idea #6: Disco on top of other distributed filesystems:

Brief explanation:  Disco has its own distributed filesystem called DDFS.  However, there is no inherent coupling between disco and ddfs.  Disco can be modified to work on top of different filesystems like HDFS and RamCloud.  There should be some changes made to disco in order to make it possible to work on top of HDFS.

Expected results:  A working version of Disco which uses filesystems like HDFS for reading and storing data.  There should be a configuration option that lets disco choose between the underlying filesystems. 


Knowledge prerequisites:  Distributed Systems, Erlang, File Systems.

Mentors:  Shayan Pooya, Prashanth Mundkur



### Idea #7: Improve the Disco UI.
There are a couple of features that should be added to Disco UI.

1. Role based authentication for Disco:
Disco needs a mechanism to separate its users and limit the interference between them.  For example, a user should be able to kill her own job but not other people's jobs; Only the administrators should be able to kill all of the jobs.

2. We should limit the amount of resources each webpage use and de-prioritize them versus the the internal calls of Disco.

3. Each user should only see the jobs launched by herself.  Only an admin should be able to see the GC statistics and change the configurations of Disco.

Knowledge prerequisites:  Http, html/javascript/css

Mentors: Shayan Pooya, Prashanth Mundkur
